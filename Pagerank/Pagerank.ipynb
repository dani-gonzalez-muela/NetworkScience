{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute PageRank on a graph that represents the web of UK around 2007. Each node is a host, and there is a link between two hosts if there is a web page in one of them pointing to a web page in the other one. This network is weighted: the weight is the number of pages that point from one host to the other one.\n",
    "\n",
    "The collection we will use, [WEBSPAM-UK2007](http://chato.cl/webspam/datasets/uk2007/), has been used in multiple studies on the effect of web spam. Feel free to decompress these files to inspect them, **but your code must read only these files in compressed form**:\n",
    "\n",
    "* ``webspam_uk2007-nodes.csv.gz`` contains (``nodeid``, ``hostname``, ``label``) records\n",
    "* ``webspam_uk2007-edges.csv.gz`` contains (``source``, ``destination``, ``weight``) records\n",
    "\n",
    "Your task is to compute PageRank twice: first considering all the links, and then ignoring links from or to a known spam host.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Code snippets needed\n",
    "\n",
    "## 0.1. Read a CSV file with a header\n",
    "\n",
    "Suppose ``FILENAME`` points to a file with the following contents:\n",
    "\n",
    "```\n",
    "a,b,c,d\n",
    "1,2,3,4\n",
    "5,6,7,8\n",
    "```\n",
    "\n",
    "The following code:\n",
    "\n",
    "```python\n",
    "with gzip.open(FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
    "    reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
    "    for record in reader:\n",
    "        print(record[\"b\"])\n",
    "```\n",
    "\n",
    "Prints:\n",
    "\n",
    "```\n",
    "2\n",
    "6\n",
    "```\n",
    "\n",
    "## 0.2. Sort a list of scores\n",
    "\n",
    "You can use the `enumerate()` function which converts a list `[a, b, c]` into `[(0,a), (1,b), (2,c)]` and then `sort()` as follows. Suppose ``score`` contains ``[0.2, 0.7, 0.4]``:\n",
    "\n",
    "```python\n",
    "hosts_by_score = sorted(enumerate(score), key=lambda x: x[1], reverse=True)\n",
    "```\n",
    "\n",
    "Will return the list `[(1,0.7), (2,0.4), (0,0.2)]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read host names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the names of the nodes into a dictionary `id2name`, and the labels into another dictionary `id2label`. They keys (nodeids) should be converted to integers using ``int(...)``. Remember in this file each record contains ``nodeid``, ``hostname``, and ``label``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import gzip\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NODES_FILENAME = \"webspam_uk2007-nodes.csv.gz\"\n",
    "INPUT_EDGES_FILENAME = \"webspam_uk2007-edges.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'webspam_uk2007-nodes.csv.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4960fad64073>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINPUT_NODES_FILENAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mid2name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mid2label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'webspam_uk2007-nodes.csv.gz'"
     ]
    }
   ],
   "source": [
    "with gzip.open(INPUT_NODES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
    "    reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
    "    id2name={}\n",
    "    id2label={}\n",
    "    for node in reader:\n",
    "        id2name[int(node[\"nodeid\"])]=node[\"hostname\"]\n",
    "        id2label[int(node[\"nodeid\"])]=node[\"label\"]\n",
    "        \n",
    "        \n",
    "print(\"%s: %s\" % (id2name[873], id2label[873]))\n",
    "print(\"%s: %s\" % (id2name[105715], id2label[105715]))\n",
    "print(\"Number of hosts: %s\" % len(id2name))    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should print:\n",
    "\n",
    "```\n",
    "bbc.co.uk: nonspam\n",
    "www.top-mobile-phones.co.uk: spam\n",
    "Number of hosts: 114529\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many hosts are labeled as spam, how many as nonspam, and how many are unlabeled, which should be the majority.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id2label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-42873c6423ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnonspam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid2label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid2label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"spam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mspam\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;31m#spam hosts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'id2label' is not defined"
     ]
    }
   ],
   "source": [
    "spam=0\n",
    "unlabeled=0\n",
    "nonspam=0\n",
    "\n",
    "for i in range(len(id2label)):\n",
    "    if(id2label[i]==\"spam\"):\n",
    "        spam+=1#spam hosts\n",
    "        \n",
    "    if(id2label[i]==\"nonspam\"):\n",
    "        nonspam+=1#nonspam hosts\n",
    "        \n",
    "    if(id2label[i]==\"unlabeled\"):\n",
    "        unlabeled+=1#unlabeled hosts   \n",
    "        \n",
    "        \n",
    "print(\"There are \"+ str(spam) + \" spam hosts\")\n",
    "print(\"There are \"+ str(nonspam) + \" nonspam hosts\")\n",
    "print(\"There are \"+ str(unlabeled) + \" unlabeled hosts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute the degree of each node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the out-degree of each node and store it in the dictionary id2degree. For this, you will need to read the edges file once. This file contains (``source``, ``destination``, ``weight``) records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of id2degree\n",
    "id2degree = {}\n",
    "N = len(id2name)\n",
    "for nodeid in range(N):\n",
    "    id2degree[nodeid] = 0\n",
    "\n",
    "with gzip.open(INPUT_EDGES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
    "    reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
    "    for edge in reader:#when a node acts as source, it means that the outdegree has to be added 1\n",
    "        source=int(edge[\"source\"])\n",
    "        id2degree[source]+=1\n",
    "        \n",
    "            \n",
    "print(\"%s: %s\" % (id2name[890], id2degree[890]))\n",
    "print(\"%s: %s\" % (id2name[1469], id2degree[1469]))\n",
    "print(\"%s: %s\" % (id2name[105715], id2degree[105715]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should print:\n",
    "\n",
    "```\n",
    "bc1.org.uk: 16\n",
    "candycaine.skinthesun.co.uk: 22\n",
    "www.top-mobile-phones.co.uk: 0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compute PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform `iterations=20` iterations with `alpha=0.85`. In each iteration, you will read the file of the graph, **without loading the entire graph in memory**. This means each iteration involves opening (and implicitly, closing) the edges file.\n",
    "\n",
    "Your code should do the following:\n",
    "\n",
    "* At the beginning, initialize the vector `pagerank` as a vector of 1/N and the vector `pagerank_aux` as a vector of 0s.\n",
    "* For `iterations` iterations:\n",
    "   * Read the graph and for every link from *source* to *destination*:\n",
    "      * Add to `pagerank_aux[destination]` the value `pagerank[source]/degree`, where *degree* is the out-degree of the source node (i.e, its number of out-links).\n",
    "   * Set *pagerank* of every node to *alpha x pagerank_aux + (1.0-alpha) x (1.0/N)*.\n",
    "   * Set `pagerank_aux` to 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 20\n",
    "ALPHA = 0.85\n",
    "N = len(id2name)\n",
    "pagerank= [1/N]*N#At the beginning, initialize the vector pagerank as a vector of 1/N and the vector pagerank_aux as a vector of 0s.\n",
    "pagerank_aux=[0]*N\n",
    "\n",
    "    \n",
    "for iterations in range (ITERATIONS):#For iterations in iterations\n",
    "    with gzip.open(INPUT_EDGES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:#Read the graph \n",
    "        reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
    "        for node in reader:#for every link from source to destination\n",
    "            source=int(node[\"source\"])  \n",
    "            destination=int(node[\"destination\"])  \n",
    "            pagerank_aux[destination]=pagerank_aux[destination]+ pagerank[source]/id2degree[source]#Add to pagerank_aux[destination]\n",
    "            #the value pagerank[source]/degree, where degree is the out-degree of the source node (i.e, its number of out-links).\n",
    "    input_file.close()  \n",
    "    \n",
    "    for i in range (N):#for every node\n",
    "        pagerank[i]=ALPHA*pagerank_aux[i] + (1-ALPHA)*(1/N)#Set pagerank of every node to alpha x pagerank_aux + (1.0-alpha) x (1.0/N)\n",
    "       \n",
    "    pagerank_aux=[0]*N#Set pagerank_aux to 0.0       \n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Nodes with largest values of PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top 20 hosts by PageRank, including the host name, and the PageRank value with 6 decimals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hosts = sorted(enumerate(pagerank), key=lambda x: x[1], reverse=True)\n",
    "for i in range(20):\n",
    "    index=top_hosts[i][0]\n",
    "    print(\"Top\"+str(i)+\": \"+id2name[index]+\" with id \"+str(index)+\" has scored \" +str(top_hosts[i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the hosts which scored a higher pagerank with thei names and id's. An important characteristic is that the most part of them star with www., which makes sense when you think about it: the most part of webpages that we visit start with these three letters. Another observation is that apart from the common \"co\" at the end of a web page, the top pages end with .gov and therefore the most important pages of uk in 2007 tended to be government pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Non-spam PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write code and run non-spam PageRank. For this, compute PageRank as before but ignore any link in which either the source or the destination is a known spam host, i.e., any node for which ``id2label[nodeid] == \"spam\"``. Consider only the edges that start and end in a ``nonspam`` or ``unlabeled`` node.\n",
    "\n",
    "This will change the degree of the nodes: the degree should not consider the links that are being ignored. Hence, we must first re-compute the degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2nsdegree={} #initilalizing id2nsdegree\n",
    "N = len(id2name)\n",
    "for nodeid in range(N):\n",
    "    id2nsdegree[nodeid] = 0\n",
    "    \n",
    "    \n",
    "with gzip.open(INPUT_EDGES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:#same as before but without counting the spam.\n",
    "    reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
    "    for edge in reader:\n",
    "            source=int(edge[\"source\"])\n",
    "            if (id2label[source]!=\"spam\"):\n",
    "                id2nsdegree[source]+=1\n",
    "                \n",
    "\n",
    "print(\"%s: %s\" % (id2name[890], id2nsdegree[890]))\n",
    "print(\"%s: %s\" % (id2name[1469], id2nsdegree[1469]))\n",
    "print(\"%s: %s\" % (id2name[105715], id2degree[105715]))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should print:\n",
    "\n",
    "```\n",
    "bc1.org.uk: 16\n",
    "candycaine.skinthesun.co.uk: 20\n",
    "www.top-mobile-phones.co.uk: 0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id2name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b2aa96f3b43c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid2name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnspagerank\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mN\u001b[0m\u001b[1;31m#At the beginning, initialize the vector pagerank as a vector of 1/N and the vector pagerank_aux as a vector of 0s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnspagerank_aux\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'id2name' is not defined"
     ]
    }
   ],
   "source": [
    "N = len(id2name)\n",
    "nspagerank= [1/N]*N#At the beginning, initialize the vector pagerank as a vector of 1/N and the vector pagerank_aux as a vector of 0s.\n",
    "nspagerank_aux=[0]*N\n",
    "\n",
    "    \n",
    "for iterations in range (ITERATIONS):\n",
    "    with gzip.open(INPUT_EDGES_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
    "        reader = csv.DictReader(input_file, delimiter=',', quotechar='\"')\n",
    "        for node in reader:\n",
    "            if(id2label[int(node[\"source\"])]!=\"spam\" and id2label[int(node[\"destination\"])]!=\"spam\"):\n",
    "                source=int(node[\"source\"])  \n",
    "                destination=int(node[\"destination\"])  \n",
    "                nspagerank_aux[destination]=nspagerank_aux[destination]+ nspagerank[source]/id2nsdegree[source]\n",
    "    input_file.close()\n",
    "    \n",
    "    for i in range (N):\n",
    "        nspagerank[i]=ALPHA*nspagerank_aux[i] + (1-ALPHA)*(1/N)\n",
    "        \n",
    "    nspagerank_aux=[0]*N       \n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hosts = sorted(enumerate(nspagerank), key=lambda x: x[1], reverse=True)\n",
    "for i in range(20):\n",
    "    index=top_hosts[i][0]\n",
    "    print(\"Top\"+str(i)+\": \"+id2name[index]+\" with id \"+str(index)+\" has scored \" +str(top_hosts[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of top scores remains the same. It is due to the pagerank algorithm: when we get rid of the spam pages we are deleting pages that have no importance(pages which send a lot of information but don't recieve any link). Therefore the algorithm was giving them a very low importance before and now the scores remain almost equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Compute spam gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute the *PageRank gain* of every host as *(Normal PageRank) / (No spam PageRank)*. And print the 20 hosts with the largest *PageRank gain*.\n",
    "\n",
    "Among the top hosts you might find many \"spam\" (business that look ilegitimate or that tend to rely on spam such as gambling, pornography, counterfeits, and scams) and \"normal\" sites (i.e., websites that look legitimate), because spammers also point to legitimate sites to disguise their actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain=[0]*N\n",
    "for i in range(N):\n",
    "    gain[i]=pagerank[i]/nspagerank[i]\n",
    "    \n",
    "top_gain = sorted(enumerate(gain), key=lambda x: x[1], reverse=True)\n",
    "for i in range(20):\n",
    "    index=top_gain[i][0]\n",
    "    print(\"Top\"+str(i+1)+\": \"+id2name[index]+\" with id \"+str(index)+\" has a gain of x\" +str(top_gain[i][1])+\n",
    "          \". Spam pagerank:\"+str(pagerank[index])+\" Non spam: \"+str(nspagerank[index]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the top hosts there are lots of business like gambling or pornography which tend to rely on spam. A part there are some \"normal\" businesses in which spammers may want to diguise their actions. The spam gives a very high gain to these nodes respecting to their pagerank values without spam, which is an interesting fact that should be considered nowadays when giving any importance to a set of webpages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
